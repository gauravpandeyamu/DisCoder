{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import argparse\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.utils as vutils\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "nz = 100\n",
    "ngf = 64\n",
    "ndf = 64\n",
    "nc = 1\n",
    "lr = .0002\n",
    "beta1 = .5\n",
    "imageSize = 28\n",
    "ncl = 20\n",
    "cls= 10\n",
    "#numPC = 1000\n",
    "batchSize = 50\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def gallery(array, ncols=3):\n",
    "    nindex, height, width, intensity = array.shape\n",
    "    nrows = nindex//ncols\n",
    "    assert nindex == nrows*ncols\n",
    "    # want result.shape = (height*nrows, width*ncols, intensity)\n",
    "    result = (array.reshape((nrows, ncols, height, width, intensity))\n",
    "              .swapaxes(1,2)\n",
    "              .reshape((height*nrows, width*ncols, intensity)))\n",
    "    return result\n",
    "\n",
    "def make_array():\n",
    "    from PIL import Image\n",
    "    return np.array([np.asarray(Image.open('face.png').convert('RGB'))]*12)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       #transforms.Normalize((0.1307,), (0.3081,)  )\n",
    "                   ])),\n",
    "    batch_size=batchSize, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       #transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batchSize, shuffle=True)\n",
    "\n",
    "trainData = train_loader.dataset.train_data.unsqueeze(1).float()/255\n",
    "trainLabels = train_loader.dataset.train_labels\n",
    "\n",
    "data_class = []\n",
    "data = torch.Tensor()\n",
    "labels = torch.Tensor()\n",
    "for i in range(0, 10):\n",
    "    inds = (trainLabels==i)\n",
    "    temp = trainData.index_select(0, inds.nonzero().squeeze())\n",
    "    data_class.append(temp)\n",
    "    data = torch.cat((data, data_class[i]),0)\n",
    "    label_class = torch.zeros(data_class[i].size(0))*0+i\n",
    "    labels = torch.cat((labels, label_class),0)\n",
    "\n",
    "#data = torch.cat((data_class[7][0:numPC], data_class[9][0:numPC]),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seed = 8#random.randint(1,1000)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        m.weight.data.normal_(0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "\n",
    "class _netG(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(_netG, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is Z, going into a convolution\n",
    "            nn.ConvTranspose2d(nz+ncl, ngf * 4, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 4),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*8) x 4 x 4\n",
    "#            nn.ConvTranspose2d(ngf * 8, ngf * 4, 3, 1, 1, bias=False),\n",
    "#            nn.BatchNorm2d(ngf * 4),\n",
    "#            nn.ReLU(True),\n",
    "            # state size. (ngf*4) x 8 x 8\n",
    "            nn.ConvTranspose2d(ngf * 4, ngf * 2, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf * 2),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf*2) x 16 x 16\n",
    "            nn.ConvTranspose2d(ngf * 2,     ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "            # state size. (ngf) x 32 x 32\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Sigmoid()\n",
    "            # state size. (nc) x 64 x 64\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "        return output\n",
    "\n",
    "    \n",
    "class _netD(nn.Module):\n",
    "    def __init__(self, ngpu):\n",
    "        super(_netD, self).__init__()\n",
    "        self.ngpu = ngpu\n",
    "        self.main = nn.Sequential(\n",
    "            # input is (nc) x 64 x 64\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf) x 32 x 32\n",
    "            #nn.Conv2d(ndf, ndf, 3, 1, 1, bias=False),\n",
    "            #nn.BatchNorm2d(ndf),\n",
    "            #nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf, ndf * 2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf * 2, ndf * 2, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # state size. (ndf*2) x 16 x 16\n",
    "            nn.Conv2d(ndf * 2, ndf * 4, 3, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*4) x 8 x 8\n",
    "            nn.Conv2d(ndf * 4, ndf * 4, 3, 1, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf * 4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            # state size. (ndf*8) x 4 x 4\n",
    "            nn.Conv2d(ndf * 4, ncl, 4, 1, 0, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        if isinstance(input.data, torch.cuda.FloatTensor) and self.ngpu > 1:\n",
    "            output = nn.parallel.data_parallel(self.main, input, range(self.ngpu))\n",
    "        else:\n",
    "            output = self.main(input)\n",
    "\n",
    "        return F.softmax(output.view(-1, ncl))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "netG = _netG(1)\n",
    "netD = _netD(1)\n",
    "criterion = nn.BCELoss()\n",
    "netG.apply(weights_init);\n",
    "netD.apply(weights_init);\n",
    "epoch = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "input = torch.FloatTensor(batchSize, nc, imageSize, imageSize)\n",
    "noise = torch.FloatTensor(batchSize, nz+ncl, 1, 1)\n",
    "fixed_noise = torch.FloatTensor(batchSize, nz, 1, 1).normal_(0, 1)\n",
    "label = torch.FloatTensor(batchSize)\n",
    "real_label = 1\n",
    "fake_label = 0\n",
    "\n",
    "netD.cuda()\n",
    "netG.cuda()\n",
    "criterion.cuda()\n",
    "input, label = input.cuda(), label.cuda()\n",
    "noise, fixed_noise = noise.cuda(), fixed_noise.cuda()\n",
    "\n",
    "input = Variable(input)\n",
    "label = Variable(label)\n",
    "noise = Variable(noise)\n",
    "fixed_noise = Variable(fixed_noise)\n",
    "\n",
    "# setup optimizer\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=lr, betas=(beta1, 0.999))\n",
    "\n",
    "classMat = torch.eye(ncl).cuda()\n",
    "phi_all = torch.rand(data.size(0), ncl)\n",
    "phi_all = phi_all/phi_all.sum(1, keepdim=True)\n",
    "z_all = torch.multinomial(phi_all,1)\n",
    "z_all = classMat.cpu().index_select(0, z_all.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def Estep(phi):\n",
    "    if(epoch==0):\n",
    "        px_z = phi/phi.sum(0).expand_as(phi)\n",
    "        _, inds = px_z.max(1)\n",
    "        return classMat.index_select(0, inds.squeeze())\n",
    "    else:\n",
    "        px_z = phi/phi_backup.sum(0).cuda().expand_as(phi)\n",
    "        _, inds = px_z.max(1)\n",
    "        return classMat.index_select(0, inds.squeeze())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "############################\n",
    "# (1) Update D network\n",
    "###########################\n",
    "\n",
    "def trainD():\n",
    "    # train with real\n",
    "    global real_loss, fake_loss, target, phi_backup\n",
    "    optimizerD.zero_grad()\n",
    "\n",
    "    input.data.resize_(real_cpu.size()).copy_(real_cpu)\n",
    "    output = netD(input)+1e-5\n",
    "    phi_backup = torch.cat((output.data, phi_backup),0)[0:3000]\n",
    "    phi_all.index_copy_(0, inds_batch, output.data.cpu())\n",
    "    z = Estep(output.data)\n",
    "    z = Variable(z)\n",
    "    z_all.index_copy_(0, inds_batch, z.data.cpu())\n",
    "    log_phi = torch.log(output)\n",
    "    \n",
    "    exponent = torch.mm(z, log_phi.t())\n",
    "    exponent2 = exponent - torch.diag(exponent).view(batchSize,1).expand_as(exponent)\n",
    "    temp = exponent2.exp()\n",
    "    px_z_inv = temp.sum(1)\n",
    "    real_loss = px_z_inv.log().sum()\n",
    "    real_loss.backward()\n",
    "    \n",
    "    target = z.data.clone()\n",
    "    fake_loss = Variable(torch.zeros(1).cuda())\n",
    "    # train with fake\n",
    "    noise.data.normal_(0, 1)\n",
    "    noise[:,nz:nz+ncl,0,0].data.copy_(z.data)\n",
    "    fake = netG(noise)\n",
    "    fake_output = netD(fake.detach())+1e-5\n",
    "    \n",
    "    log_phi_fake = torch.log(fake_output)\n",
    "    fake_loss = (fake_output*log_phi_fake).sum()\n",
    "    fake_loss.backward()\n",
    "\n",
    "    optimizerD.step()\n",
    "    return real_loss.data[0], fake_loss.data[0]\n",
    "    \n",
    "############################\n",
    "# (2) Update G network: \n",
    "###########################\n",
    "\n",
    "def trainG():\n",
    "    optimizerG.zero_grad()\n",
    "    global target\n",
    "    z = target.clone()\n",
    "    z = Variable(z)\n",
    "    fake = netG(noise)\n",
    "    output = netD(fake)+1e-5\n",
    "    log_phi = torch.log(output)\n",
    "    #loss = (z*log_phi).sum()*-1\n",
    "\n",
    "    exponent = torch.mm(z, log_phi.t())\n",
    "    exponent2 = exponent - torch.diag(exponent).view(batchSize,1).expand_as(exponent)\n",
    "    temp = exponent2.exp()\n",
    "    px_z_inv = temp.sum(1) \n",
    "    loss = px_z_inv.log().sum()\n",
    "    loss.backward()\n",
    "    optimizerG.step()\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "niter = 25\n",
    "sigma = .5\n",
    "import numpy as np\n",
    "outf = '/home/gaurav/Desktop/Research/models/github/IBFNN/'\n",
    "label = 0\n",
    "phi_backup = torch.rand(3000, ncl).cuda()\n",
    "posterior = torch.zeros(data.size(0), ncl)\n",
    "alpha = 1\n",
    "for epoch in range(100):\n",
    "    netD.train()\n",
    "    netG.train()\n",
    "    real_loss_all = 0\n",
    "    fake_loss_all = 0\n",
    "    shuffle = torch.randperm(data.size(0))\n",
    "    for i in range(0, data.size(0), batchSize):\n",
    "        inds_batch = shuffle[i:i+batchSize]\n",
    "        real_cpu = data.index_select(0, inds_batch)\n",
    "        real_loss, fake_loss = trainD()\n",
    "        trainG()\n",
    "        \n",
    "        real_loss_all += real_loss\n",
    "        fake_loss_all += fake_loss\n",
    "        \n",
    "\n",
    "    print(str(real_loss_all) + ' ' + str(fake_loss_all))\n",
    "\n",
    "    \n",
    "\n",
    "    _, indices_fake = phi_all.cpu().max(1)\n",
    "    indices_fake = indices_fake.squeeze().float()\n",
    "    indices_real = labels\n",
    "    intersect = torch.zeros(ncl,cls)\n",
    "    for i in range(0,ncl):\n",
    "        for j in range(0,cls):\n",
    "            intersect[i][j] = ((indices_fake==i)*(indices_real==j)).sum()\n",
    "\n",
    "    accuracy = intersect.max(1)[0].sum()/intersect.sum()\n",
    "    print('Purity of clusters:',accuracy)\n",
    "\n",
    "\n",
    "    netG.eval()\n",
    "    nose = torch.zeros(200,120,1,1).cuda()\n",
    "    nose = Variable(nose)\n",
    "    target = torch.zeros(200,20)\n",
    "    nose.data.normal_(0, 1)\n",
    "    nose[:, nz:nz+ncl].data.zero_()\n",
    "    target.zero_()\n",
    "    k=0\n",
    "    for i in range(0,200,10):\n",
    "        target[i:i+10,k].fill_(1)\n",
    "        k+=1\n",
    "    nose[:,nz:nz+ncl].data.copy_(target)\n",
    "    fake = netG(nose)\n",
    "    result = gallery(fake.permute(0,2,3,1).data.cpu()[10:].numpy(), 10)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(result[:,:,0], cmap='gray')\n",
    "    plt.savefig(\"./MNIST.png\", bbox_inches='tight')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
